### 部署监控系统

性能指标(如：CPU、Memory、Load、磁盘、网络等）
1.容器、Pod相关的性能指标数据
2.主机节点相关的性能指标数据
3.容器的网络性能，如http、tcp等数据
状态指标

1. kubernetes资源对象（Deployment、Daemonset、Pod等）的运行状态指标

2. kubernetes平台组件（如kube-apiserver、kube-scheduler、etcd等）的运行状态指标

### 监控方案

1. Heapster、InfluxDB、Grafana
每个Kubernetes节点的Kubelet内含cAdvisor，暴露出API，Heapster通过访问这些端点得到容器监控数据。它支持多种储存方式，常用的是InfluxDB。这套方案的缺点是数据来源单一、缺乏报警功能以及InfluxDB的单点问题，而且Heapster也已经在新版本中被deprecated(被metrics server取代)

2.Metrics Server、InfluxDB、Grafana
Kubernetes从1.8版本开始，CPU、内存等资源的metrics信息可以通过 Metrics API来获取，用户还可以通过kubectl top直接获取这些metrics信息。Metrics API需要部署Metrics-Server。

3.node-exporter、 Prometheus、Grafana
通过各种export采集不同维度的监控指标，并通过Prometheus支持的数据格式暴露出来，Prometheus定期pull数据并用Grafana展示，异常情况使用AlertManager告警

#使用组件
#node-exporter、 alertmanager、  grafana、  kube-state-metrics、  Prometheus

#组件说明
MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如kubectl,hpa,scheduler等。
NodeExporter：用于各node的关键度量指标状态数据（服务器CPU、内存、磁盘、I/O）。
KubeStateMetrics：收集kubernetes集群内资源对象数据，制定告警规则。
Prometheus -adapter: 自定义监控指标与容器指标
Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数据，通过http协议传输。
Grafana：是可视化数据统计和监控平台。
Alertmanager：实现短信或邮件报警。



- 安装NFS服务端

```
yum install -y nfs-utils
```

- 创建nfs目录

```
mkdir -p /ifs/kubernetes
```

- 修改权限

```
 chmod -R 777 /ifs/kubernetes
```

- 编辑export文件

```
vim /etc/exports
/ifs/kubernetes *(rw,no_root_squash,sync)
```

- 修改配置启动文件

```sh
cat >/etc/systemd/system/sockets.target.wants/rpcbind.socket<<EOFL
[Unit]
Description=RPCbind Server Activation Socket
[Socket]
ListenStream=/var/run/rpcbind.sock
ListenStream=0.0.0.0:111
ListenDatagram=0.0.0.0:111
[Install]
WantedBy=sockets.target
EOFL
```

- 配置生效

```
exportfs -f
systemctl restart rpcbind 
systemctl enable rpcbind
systemctl restart nfs 
systemctl enable nfs
```

- 所有node安装

```
yum -y install nfs-utils
```

- 部署PVC 

```
[root@master-249-160 ~]# mkdir nfs

[root@master-249-160 nfs]# vim nfs-rbac.yaml

```

>  nfs-rbac.yaml

```yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  name: nfs-client-provisioner
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: default
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: default
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
```

> nfs-class.yaml

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: managed-nfs-storage
provisioner: fuseim.pri/ifs # or choose another name, must match deployment's env PROVISIONER_NAME'
parameters:
  archiveOnDelete: "true"
```

> **nfs-deployment.yaml**

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: nfs-client-provisioner
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          imagePullPolicy: IfNotPresent
          image: quay.io/external_storage/nfs-client-provisioner:latest
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: fuseim.pri/ifs
            - name: NFS_SERVER
              value: 10.122.249.165
            - name: NFS_PATH
              value: /ifs/kubernetes
      volumes:
        - name: nfs-client-root
          nfs:
            server: 10.122.249.165
            path: /ifs/kubernetes
```



- 查看

```sh
[root@master-249-160 nfs]# kubectl get StorageClass
NAME                  PROVISIONER      AGE
managed-nfs-storage   fuseim.pri/ifs   71s
[root@master-249-160 nfs]# kubectl get pods
NAME                                     READY   STATUS    RESTARTS   AGE
nfs-client-provisioner-97969d4d7-j8bml   1/1     Running   0          49s
```

